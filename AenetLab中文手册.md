# AenetLab / NNAP中文手册



[TOC]

## 简介

AenetLab 是 NNAP 势能面训练包的集成环境，使用 AenetLab 你可以高效地完成：

* **批量化风格化的结构-能量数据集产生与连接**
* **笛卡尔空间矢量到指纹（对称）矢量的转换**
* **适配多种优化算法的神经网络训练**
* **一键式的标准测试与绘图**
* **灵活的自定义扩展**

AenetLab 可以被理解为一个高度集成化的 NNAP 外部 python 接口， NNAP 的工作流在这里被抽象为一个包含数据集创建、指纹矢量产生以及神经网络训练等方法的AenetLab类；在 NNAP 整个训练势函数的工作流中所需的所有参数，都可以通过 JSON 文件的形式进行加载，不再需要用户手动书写 aenet 的输入配置文件。 AenetLab 采用工作流的设计思路，有完善的断点重启机制，并且无需用户重新配置，终断的任务只需要再次提交任务续算即可。

相比于 aenet ，AenetLab 保留了原版的 *generate* 以及 *train* 方法，并新加入了 *create* 方法，该方法提供多种多样的构型创建方法（包括体态与表面构型），这使得 AenetLab 可以真正覆盖整个人工神经网络势能面训练的工作流。并且该方法可以很好地支持用户自定义创建方式（包括结构生成方式与能量计算方式），对于有特殊研究需求的用户，这将是非常友好的一个功能。如果想要了解如何开发自定义的构型创建方法，请查看 **开发者指南** 。

除此之外， AenetLab 还内置了一些常用的工作脚本，这些脚本将会在用户创建Lab文件夹时自动导入。它们会帮助用户完成一些十分重要的测试、数据分析以及绘图任务，例如对于 *earlystop.py* ，它将从迭代的训练步中挑选测试集误差最小的一步，输出到指定文件夹下并在屏幕上打印该步的信息。如果想了解更多的详细信息，请查看  第 **4** 章。

总而言之，编写 AenetLab 的初衷是为了在 NNAP 的基础上完善总体流程，使用户可以更高效地完成构建神经网络势能面的任务。

<div id="text1.1"></div>
## 1 安装指南

### 1.1 主体安装

由于 python 的即时编译特点，在安装 AenetLab 主体时，用户不需要额外再进行任何复杂的编译。

1）对于已经安装成功 aenet 的用户，只需要将 AenetLab 的压缩包解压到 `aenet` 主目录下的 `python/aenet` 子目录中，并进入 AenetLab 目录，命令行输入<kbd>./build_ext.sh</kbd>即可。如果屏幕打印成功信息，则可以将当前的 AenetLab 路径加入到环境变量中。**注意：我们强烈建议用户在环境变量中只保留一个指向最新版本 AenetLab 的路径，因为多个路径会直接打乱Lab文件夹的创建逻辑并产生意想不到的错误。**

2）对于没有安装过 aenet 的用户，可以在 [aenet 的官网](http://ann.atomistic.net/) 或 [aenet 的 Github 项目](https://github.com/atomisticnet/aenet) 中找到完整的源代码和安装指南，在安装测试成功后进行上述1步骤即可。

当上述步骤完成后，用户即可以进入任一目录下，在命令行输入<kbd>lab_create</kbd>，此时会开启Lab目录的创建引导，完成引导后会在当前目录创建输入的同名子目录。

可以顺利完成上述操作，则说明 AenetLab 的主体部分已经安装成功。

<div id="text1.2"></div>
### 1.2 库依赖

AenetLab 与 aenet 的 python 库依赖基本一致，因此标准版本是不需要额外安装其他库的。但是由于 AenetLab 支持用户自己自定义式地添加更多风格的 *create* 方法，对于不同的拓展版本将会有不同的库依赖。下面给出用户需要预装的python包，除 anaconda 本身外，其他的库均需要通过anaconda自身的conda（联网情况）或者pip（集群等单机情况）进行安装，否则会出现无法找到库的错误：

|   库名   | 推荐版本 |
| :------: | :------: |
| anaconda |  5.2.0   |
|   ase    |  3.19.2  |
| pymatgen |  >2.0.0  |

注意：根据长期测试的结果，不同版本的 anaconda 与 ase 之间可能因为 numpy 库的API接口调用而存在冲突，然而这个冲突并不会导致 aenet 安装失败，因此即使用户安装成功也可能会出现报错。为了防止这种潜在的错误影响后续的计算，我们建议用户在安装 aenet 后进入`path_to_aenet/python/aenet/tests`中并运行<kbd>python test_ase.py</kbd>进行测试。运行通过即可以确定用户安装的anaconda版本与ase版本是否有冲突。

对于在集群等单机环境下安装 aenet 及 AenetLab 的用户，可以不用安装 pymatgen 库，但是这意味着用户无法直接通过 AenetLab 的工作脚本 *get_crystals.py* 从 [Materials Project](https://materialsproject.org/) 中去批量地获得晶体构型，相应的解决方法参见 [**4.1**](#text4.1) 。

<div id="text1.3"></div>
### 1.3 外部接口配置与编译

AenetLab 目前包含三类接口，一类用于调用 VASP 进行构型的静态势量计算，第二类用于链接训练产生的势函数文件与分子动力学模拟框架，第三类用于调用Materials API (MAPI) 来批量获取晶体构形。

 三类接口中只有第一类是 AenetLab 工作所必须的，其余两类用户可以根据自己的安装环境与习惯来自行选择是否配置（为了更好的体验，我们强烈建议用户完整配置全部三类接口，但是**超算等封闭的离线服务器无法正常使用MAPI接口（第三类）**）。当然，我们也十分欢迎用户扩展以上三类接口来适配更多的任务与场景。

#### 1.3.1 VASP 调用接口

该接口是基于`ase.calculators.Vasp`构建的一个自动化计算接口，想要了解其构造逻辑以及使用方法，请参阅 **开发者指南** 。由于VASP为闭源软件，所以如果想要成功调用，则需要在系统的环境变量中指定VASP的赝势库路径`VASP_PP_PATH`以及调用命令`VASP_COMMAND`，详情参见 [ASE vasp doc](https://wiki.fysik.dtu.dk/ase/ase/calculators/vasp.html) 。

#### 1.3.2 分子动力学接口

目前 AenetLab 支持 Lammps 的势函数链接接口，该接口需要与 Lammps 源文件一起进行编译，编译的流程如下：

! (**未完**）

#### 1.3.3 MAPI 调用接口

该接口是基于REST(REpresentational State Transfer)原则利用 Materials Project 数据集构建的晶体构型高通量接口，任意支持 http 请求的语言都可以完成对该 API 的一个具体实现。这里我们选择 Python Materials Genomics (pymatgen) 库的内置包装模块 MPRester ，该模块直接提供了一个高效并行的高级包装，用户无需任何手动地配置 http 请求即可使用该接口访问 Materials Project 的数据集资源，详情参见 [pymatgen.matproj.rest](https://pymatgen.org/usage.html) 。

由于使用 MAPI 需要提供 API key 进行身份安全校阅，因此需要用户提前注册 MP 用户资格（免费）。注册成功后，每位用户的 API key 将出现在 [dashboard](https://materialsproject.org/dashboard) 中。

成功获得 API key 后，用户需要进行 API key 的本地配置才能使用 AenetLab 内置的工作脚本 *get_crystals.py* 。配置方法非常简单，在终端命令行输入：

```pmg config --add PMG_MAPI_KEY &lt;USER_API_KEY&gt;
pmg config --add PMG_MAPI_KEY <USER_API_KEY>
```

运行之后用户的 API key 就会存放到系统用户目录下的 *.pmgrc.yaml* 文件中，之后用户使用 *get_crystals.py* 或其他应用了MPRester模块的脚本时，pymatgen会自动读取该文件中的 API key ,用户无需重复配置。

<div id="text2.1"></div>
## 2 工作流

### 2.0 名词解释

在具体地工作流介绍之前，有必要对工作流中的一些名词做出解释：<a name="text2.0"></a>

**Lab目录**  工作流中的基本工作单位，AenetLab 可以对其中的数据集进行拓展、识别、筛选、连接等一下列操作。建议用户对于每一种不同风格的数据集都单独创建一个Lab目录。

**过程(process)**  工作流的完整执行版本，包含了从准备数据到表征到训练再到后处理的整个流程。通常得到可以应用的神经网络势函数需要好几个过程的迭代。

**任务(task)**  工作流的执行版本，由一系列的工作脚本实现。既可以通过一个任务覆盖一整个 过程 ，也可以使用多个任务拼接完成，AenetLab 提供了一些快捷的工作脚本帮助用户完成一些必需的任务，见[第 4 章](#text4)。

**数据集目录**  Lab目录下的由 *create* 方法生成的子目录，其中存放了标记总能的XSF文件以及指向这些文件的*list* 文件。

**表征与训练目录**  每一条工作流都可以包含数据集的表征与训练任务，为了更好地使用与管理，如果用户调用了相应任务的启动方法，则会首先为该任务在当前 Lab 目录下生成对应的子目录，具体参见 [2.5](#text2.5)。

**训练步(epoch)**  专指在训练任务中，进行一次前向传播(损失计算)+一次反向传播(更新权重)。

<a name="text2.1"></a>

### 2.1 创建Lab目录

AenetLab 所有的操作都是在Lab目录中进行的，用户在完成了 [**1.1**](#text1.1) 的测试之后，就可以通过 <kbd>lab_create</kbd> 命令并按照引导来实现一个初始Lab目录的创建。该创建过程会将全部**工作脚本**以及一个 *template.json* 复制到该Lab目录下，其中 *template.json* 的作用是提供一个参数配置的模板，其中以JSON文件格式包含了所有 AenetLab 可以设置的参数，用户可以根据研究的需求来调整相应参数的初值。

在开始工作前，请熟悉 AenetLab 的基本工作逻辑：

每一个Lab目录**有且仅有一个**参数配置文件，是用来实例化（初始化） AenetLab 类的，只有经过实例化的 AenetLab 才可以正常调用类中定义的函数（方法）；

而每个Lab目录可以有多个工作脚本 ，它们通过实例化后的 AenetLab 对象来完成不同的任务。因此每个工作脚本都包含一块实现实例化的代码。其中需要注意的是，**AenetLab 内置的工作脚本只识别 *.json* 后缀的文件**，因此建议用户将参数配置文件以该后缀命名。

```python
import aenet.AenetLab as AL
import json

with open(json_name,'r') as f:       #内置的工作脚本只识别.json后缀的文件
    textjson = json.load(f)
    aelab = AL.AenetLab(textjson)    #此处为AenetLab实例化
```

对于每一个由<kbd>lab_create</kbd>创建的 Lab 目录，都会为其自动添加上 Lab 目录的识别标签 *.islab* 以及其中的任务序号 *.taskid*  其中任务序号从 1 开始计数，到完成整个训练过程为结束，结束之后其会自动累计为 2 ，以此类推。

为了方便用户整理工作流程， AenetLab 提供了任务回退脚本 *rewind.py*，如果当前任务出现任何异常，用户只需要执行该脚本便可以退回当前序号的初始状态，详见 [4.5](#text4.5) 。

<a name="text2.2"></a>

### 2.2 参数配置与修改

AenetLab 的实例化使用从参数配置文件中的 “参数字典” 来对 AenetLab 进行配置。各参数的大分类与细节将在第 **3** 章中呈现。这里给出json参数配置文件的局部作为一个例子：（**注意JSON格式下只识别双引号内部为一个字符变量**）

```json
...	
	"Create":{
    	"style"         :   "VorInsert",
        "taylor"        :   true
    },

    "CreateDetails":{
        "Dimer":{
            "pair"      :   "CuCu",
            "nsamples"  :   10,
            "drange"    :   [1.4,2.8],
            "outdir"    :   "Dimer_Xsfs"
            },

        "Disturb":{
            "initdir"   :   "CuZr",
            "nsamples"  :   10,
            "defm_lim"  :   "default",
            "ratt_size" :   "default",
            "del_perc"  :   "default",
            "replicate" :   "default",
            "rep_uplim" :   "default",
            "index"     :   "default",
            "isdataset" :   "default",
            "seed"      :   "default",
            "inc_init"  :   "default",
            "outdir"    :   "Disturb_Set"
            },
...
```

通常情况下，用户只需对json文件中一些重要的参数进行配置，例如研究体系的元素、神经网络隐藏层、数据集风格、测试集比例等。对于缺省的参数，用户只需设置“default”即可，大多数的参数都拥有缺省值，详情见第 **3** 章。

如果AenetLab 已经完成了实例化，而用户需要对之前的参数进行修改，那么有两种方法可供选择：

1）直接修改 *template.json* 中的参数值。这种方式适合修改的参数量比较少，且整个过程中有多个任务重复使用该参数的情况，例如预设 *Types* 、*Unit* 等多个全过程共享的参数。**注意：手动修改json文件的操作会一直保留！**

2）使用 ***set()*** 方法也可以很方便地完成这一操作。例如，如果用户想要同时完成多种风格的数据集创建（见2.3节与[3.6节](#text3.6)），此时通过手动修改json文件再多次运行工作流的方式显得非常低效，利用 ***set()*** 方法来实现参数的调整则可以更便捷地在脚本中实现参数的修改，如下：

```python
...
	aelab = AL.AenetLab(textjson)
	aelab.create()
	aelab.set(textjson,[['Create','style','ClusterCut']])
	aelab.create()
    aelab.set(textjson,[['Create','style','Disturb'],
                        ['CreateDetails','Disturb','nsamples',15]])
    aelab.create()
```

***set(old_d, args_keyvalues)*** 是定义在 AenetLab 类上的方法，因此其调用遵循常规的Class类方法调用语法，用户在使用该方法前，必须将 AenetLab 类实例化。参数解释如下：

|     参数名     |     参数类型     | 是否必选 |                           其他描述                           |
| :------------: | :--------------: | :------: | :----------------------------------------------------------: |
|     old_d      |      字典类      |    是    |                    从json文件中读取的字典                    |
| args_keyvalues | 双层的列表或元组 |    是    | 内层[0:-1]按顺序构成一条索引钥匙，而[-1]为更改的目标值(索引语法与python一致) |

**注意：使用该方法设置的参数不会覆盖json文件内的参数内容，只影响脚本内 AenetLab 对象的参数字典**。

Tips：由于json文件中的参数将被加载为字典，因此字典树的不同子代分支是可以互相独立的，允许用户保留不同分支的设置以方便更改与调用。在 AenetLab 框架下，这些相对独立的分支基本都归纳为了 *"##Details"* 。例如用户数据集创建的风格既有 *VorInsert* 又有 *AbinitioMD* ，那么用户可以一次性在 *CreateDetails* 中将这两个风格内部的参数都设置好，之后用户只需要通过***set()***更改 *create-style* 就可以实现快速的风格切换。

<a name="text2.3"></a>

### 2.3 创建数据集

在进行势能面训练时，最关键的一步就是创建相应的数据集，数据集的质量将直接影响最终训练结果。用户在完成参数配置后就可以开始着手数据集的创建，AenetLab 中大部分数据集创建的风格，都需要指定初始的数据集(*initdir*)；而对于一个从零开始的训练任务，获取研究体系的**晶体数据集**作为这个 *initdir* 将是至关重要的。可以使用工作脚本 *get_crystals.py* 在联网状态下轻松完成这一步骤，详情参见 [**4.1**](#text4.1) 。

```python
#紧接AenetLab实例化
	aelab.create()
```

在 AenetLab 类的 create 方法中，用户需要进行下面三种配置：

1）**风格配置**  经验上，数据集的多样性与覆盖范围越宽泛越好，并且可以通过有针对性地引入特定构型来提高网络的泛化性能。因此 AenetLab 支持多种数据集创建风格，用户可以通过设置参数 *Create-style* 来指定当前数据集创建的风格，并通过调整 *CreateDetails* 中相应的风格细节参数来实现精准地控制。目前已支持的风格包括形变采样，动力学采样以及多面体间隙采样，详情见[3.6](#text3.6)。

2）**DFT配置**  对于训练神经网络势能面而言，有效的数据集格式必须包含构型的原子笛卡尔坐标与DFT手段计算出的总势能。在 aenet 中，数据集文件格式统一采用了自定义能量的XSF格式，通过 *xml2xsfs* 脚本处理 Vasp 的输出文件 *vasp.xml* 可以得到固定格式的XSF文件，因此高通量的DFT计算与处理需要用户额外编写调用程序。而在 AenetLab 中，这些繁琐的操作过程已经被很好地封装，用户将不需要进行任何格式转换上的操作，只需要用户完成 **1.3** 中Vasp接口配置，并通过配置 *CreateDetails-Vasp* 或*CreateDetails-VaspCustomized* 来确定，当然用户也可以通过添加自定义接口来连接其他的DFT计算工具。

 AenetLab 保留了自定义接口，用户可以在 AenetLab 设定的接口规范下对 AenetLab 源码进行拓展。

<a name="text2.4"></a>

### 2.4 Taylor展开以及数据集的连接

研究表明，使用能量作为单一指标训练的精度，不如以能量与力进行联合训练所达到的精度。但是力指标的自由度要远高于能量指标，导致数据集占用内存过高。因此为了平衡这两个矛盾，N. Artrith et al 提出了基于泰勒一阶展开的[近似算法](https://www.nature.com/articles/s41524-020-0323-8)，该框架下将力的信息等效为对于原始构型的一阶微扰展开。 AenetLab 内置了实现该算法的模块，用户可以通过设置参数 *Taylor - do_taylor* 来选择是否为生成泰勒展开集，同样可以在参数细节配置 *TaylorDetails* 中对泰勒展开集的生成细节进行精准控制。

AenetLab 可以自动识别当前 Lab 目录中的数据集目录，当用户设置  *do_taylor* 参数为*true* 时，默认这些识别到的数据集需要进行 Taylor 展开。当用户需要单独控制某一些数据集的 Taylor 展开时，则需要

AenetLab 支持多个当前 Lab 目录以外的数据集互联，用户通过设置参数 *Taylor-extpaths* 中的绝对路径（以'/'开头），就可以实现多个数据集的快速连接。用户必须为指定的绝对路径添加逻辑键值以确定相应数据集的 Taylor 展开是否进行。

```json
...
"Taylor":{
    ...
    "extpaths"      :   {
        "abspath/to/labdir1"  :  true,
        "abspath/to/labdir2"  :  false,
        "abspath/to/labdir3"  :  true
        ... }
    },
...
```

AenetLab 目前支持两种规范的数据集连接：

1）**纯XSF集目录**    

​		这种目录下，不存在 *list* 文件等可以快速标记数据文件的辅助文件，几乎是纯的XSF集。

2）**Lab目录下的[数据集目录](#text2.0)**

​		存在 *list* 文件等可以快速标记数据文件的辅助文件。

对于1)的 *extpaths* 的指定方式为：直接指定该XSF集目录。

对于2)的 *extpaths* 的指定方式为：指定该数据集目录所在的 Lab 目录 或 直接指定该数据集目录。

**注意：以上两种数据集之间可以互相转换，详见 [4.6](#text4.6) 。**

---

当 AenetLab 尝试链接一个给出的目录时，会检查目录下是否有合法的 *.isdir* 文件：

如果存在，则说明该目录是属于一个 Lab 目录，此时会对该目录内的所有子目录进行扫描，如果子目录下存在合法的 *.isdataset* 文件，则将该子目录识别为一个有效数据集，并根据该子目录下 *list* 文件中的文件名列表进行相关链接操作。

如果不存在，则说明该目录属于一个纯XSF集，大部分使用原始 aenet 开发的势函数数据集都是这一类，此时该数据集中不存在 *list* 文件，因此会直接遍历目录下的所有可读文件，并选取后缀为 *.xsf* 的文件进行链接。

<a name="text2.5"></a>

### 2.5 启动表征与训练

用户在完成了 **2.3**-**2.4** 的数据集准备与连接工作后，可以开始着手数据集的表征与训练工作。同样地，使用 AenetLab 的用户不再需要手动地为表征与训练过程创建任何输入文件。

完成 *template.json* 文件相应参数块的设定并实例化 AenetLab 之后，便可以通过调用该对象上的 *generate* 方法来启动表征任务：

```python
#此处接已创建好数据集后
    aelab.generate()
```

表征任务启动后，首先会在当前 Lab 目录下新建一个承包该任务的子目录，即**表征目录**(初始名为*01-generate*)。之后，AenetLab 根据 *Generate* 参数块以及 *Types-...-E_atom* 的内容，在子目录中为 generate.x 构造输入配置文件(初始名为 *generate.in*)；并根据 *Types-...-stp_style* 以及 *StpDeatils* 的内容构造指纹函数配置文件(命名规则为“元素+.stp”)详情查看 3.1 与 [3.8](#text3.8)。

最终表征任务完成会输出一个初始名为 *out.train* 的二进制文件，该文件包含了表征后的全部数据集信息，将直接作为后续训练任务的输入数据文件。另外，表征任务会实时输出log文件，初始名为 *Info_generate* 。

需要注意的是，generate 任务目前还不支持断点续算功能，当用户使用 *behler2011* 基组时，需要仔细斟酌三体项的个数以保证任务时间在可接受范围之内。

---

完成上述表征任务后，可以继续调用对象上的 *train* 方法来启动训练任务：

```python
#此处接已完成表征任务后
	aelab.train()
```

训练任务启动后，首先会在当前 Lab 目录下新建一个承包该任务的子目录，即**训练目录**(初始名为*02-train*)。之后，AenetLab 根据 *Train* 以及 *TrainDetails* 参数块以及 *Types-...-nnodes/acfuns* 的内容，在子目录中为 train.x 构造输入配置文件(初始名为 *train.in*)。<a name="traintask2.5"></a>

最终训练任务完成会针对每种指定的元素输出相应的势函数文件，命名方式为“元素.隐藏层结构.nn”，存放的目录为 *"?_nnpots"* 。另外，训练任务会实时输出log文件，其初始名为 *Info_train*，存放目录为*"?_step_details"*。其中 *?* 指代的是训练任务的序号（AenetLab 中会自动按照顺序为训练任务进行标号）。**注意：训练未结束时，所有的训练输出文件都留存在训练目录中，只有训练结束后才会移入子目录进行存放。**

训练任务支持断点续算功能，只要在子目录中保留有 restart 与 rngstate 文件即可重启之前中断的训练任务，并且 AenetLab 会自动根据上一次任务的断点 epoch 来作为本次任务 epoch 的 offset 起点。除了断点续算功能，AenetLab 还支持断点早停功能，用户可以根据log文件中的信息监控训练任务是否出现过拟合，当判断出现过拟合时，可以手动中止任务，并调用早停分析脚本 earlystop.py 来取出早停点附近的记录并作为最终输出，详情见 [4.2](#text4.2) 。



### 2.6 验证与后处理

计算效率、精度以及迁移性，是神经网络势函数能否在分子动力学模拟中应用的关键。理想的势函数应该是低计算复杂度、高精度以及强迁移的， 然而由于数据集的不完整性以及噪声，往往训练并不会直接得到理想的势函数，因此有必要对势函数的各项性能进行严格地验证。

---

效率方面，可以通过 lammps 等分子动力学模拟软件进行分析测试。在 AenetLab 中，如果用户配置了 lammps 的分子动力学接口，可以很简单地对2.5中得到的势能面文件进行效率测试。在 Lammps 的log文件中找到类似如下内容。

> Loop time of 4727.85 on 160 procs for 250000 steps with 3629 atoms
>
>   		Performance: 9.137 ns/day, 2.627 hours/ns, 52.878 timesteps/s
> 	    100.0% CPU use with 160 MPI tasks x no OpenMP threads

势函数文件的计算速度首先可以与节点数或MPI task数进行标度(下图测试环境为天河二号，单节点满编20核)，正常情况下其满足如下图般的近似线性。



<img src="D:\CSRC\我的工作\CuZr-O体系资料调研\speed.png" alt="avatar" style="zoom:65%;" />

如果用户在测试时发现测试结果不满足这一关系，可能是源于以下情况：

1）**每个MPI task的原子数分配不均**     可以通过调用lammps中的[fix balance](https://lammps.sandia.gov/doc/fix_balance.html)命令来解决这个问题。

2）**MPI task的数量超过了原子数**     选择用更少的核数或换用更大的体系。

在满足计算速度与节点数之间的线性标度后，用户还可以通过在不同原子数的体系进行单位节点速度标度，即将速度-节点图中的斜率与体系原子数进行标度。

---

精度方面，AenetLab 使用测试精度这一指标用于来检验训练过程。

测试精度是训练任务中测试集上可以达到的精度，要获得统计意义上的测试精度，需要在相同参数下运行多次训练任务（每个训练任务之间在划分训练-测试集时是随机，因此多次并行地训练可以获得势函数统计意义上的测试精度）。AenetLab 在训练任务中产生的log文件(Info_train)内详细地记录了一次训练任务中每一个[训练步](#text2.0)的前向传播计算出的单位原子能量误差，单位为eV/atom，如下例。

>​           |------------TRAIN-----------|  |------------TEST------------|
>
>   epoch             MAE          <RMSE>             MAE          <RMSE>
>       0    1.938363E+00    2.252931E+00    1.886281E+00    2.162379E+00 <
>       1    1.938363E+00    2.252931E+00    1.886281E+00    2.162379E+00 <
>       2    9.930486E-01    1.321997E+00    8.142546E-01    1.165639E+00 <
>       3    5.759063E-01    7.377562E-01    5.440417E-01    7.346959E-01 <
>       4    4.917168E-01    6.488032E-01    4.839892E-01    6.792299E-01 <
>       ... ...

其中MAE为平均差，RSME为均方误差。测试精度可以很直观地反映出模型是否出现了过拟合，如下图(该图引自[aenet](https://www.sciencedirect.com/science/article/abs/pii/S0927025615007806))：

<img src="D:\CSRC\我的工作\CuZr-O体系资料调研\overfitting.png" alt="avatar" style="zoom:65%;" />

当训练集上的误差保持下降而测试集上的误差开始上升时，即出现了过拟合。过拟合会极大地降低模型的可迁移性，因此训练任务的终极目标一定是在保证不出现过拟合的前提下尽可能地降低误差。AenetLab 提供便捷的工作脚本实现这一目标，见 [4.2](#text4.2) 。

---

迁移性方面，利用在全新生成的数据集（即独立于训练集与测试集之外的验证集）上的预测误差表现来刻画势函数的迁移性强弱。预测验证与在精度方面的早停操作虽然都是为了保证势函数的迁移性，但预测验证由于"预测"这一属性的存在，不仅可以检验势函数的真实迁移能力，而且如果验证集上表现不佳，还可以直接将验证集加入原有数据集开启下一轮的迭代过程。AenetLab 中同样内置了实现该功能的工作脚本，见 [4.3](#text4.3) 。

经过多轮过程的迭代与筛选，可能会获得迁移表现更好的势函数模型，但同时也有可能因为新数据的噪声使得误差有所上升。目前 AenetLab 版本兼顾迁移性与精度的方式还是根据用户的经验，之后的版本中会逐步更新相关的调优功能。

---

对于势函数而言，还有一种简单定性的验证方式，使用双原子对模型来预测能量-键长曲线(dimer曲线)。通常好的神经网络势函数是可以基本预测出一条类LJ线形的dimer曲线，如下图所示：<a name="dimer"></a>

<img src="D:\CSRC\我的工作\CuZr-O体系资料调研\dimer.png" alt="avatar" style="zoom:55%;" />

AenetLab 内置了实现该功能的工作脚本，见 [4.4](#text4.4) 。

注意该方法只能定性地验证势函数是否符合基本的键对规律，以免在分子动力学模拟时引入非物理的相互作用。严格意义上的神经网络势能面有效性，需要将其具体地应用到分子动力学模拟中，通过计算相应物理统计量并与基准(ground truth)对比来验证。



## 3 参数详情（完善中）

目前 AenetLab 的全部参数都会放置在 *template.json* 中，其中大部分参数都存在缺省值，直接用设置参数值为字符变量 *"default"* 即可缺省该参数。如果在下面的参数介绍中，缺省值一栏中显示"无"，那么说明这个参数必须被指定，如果不指定或者类型不正确将无法正常运行 AenetLab 。另外再次强调：**JSON格式下只识别双引号内部为一个字符变量** 。

### 3.1 Types

每个工作流必须明确研究体系相关元素(**Types**),例如对于一个CuZr合金体系可以做出如下设置：<a name="example1"></a>

```json
...	
	"Types":{
    	      "Cu":{
        	      "lammps_number" : 1,
            	  "E_atom"        : "default",
	              "stp_style"     : "Spherical_Chebyshev",
    	          "nnodes"        : [30,30],
        	      "acfuns"        : ["swish","swish"]
            	  },
          	  "Zr":{
              	  "lammps_number" : 2,
                  "E_atom"        : "default",
                  "stp_style"     : "Spherical_Chebyshev",
                  "nnodes"        : [30,30],
                  "acfuns"        : ["swish","swish"]
                  }
      		},
...
```

参数及描述如下：

| 参数名        | 变量类型 | 描述                                                         | 缺省值 |
| ------------- | -------- | :----------------------------------------------------------- | ------ |
| lammps_number | int      | 用户在LAMMPS命令( *mass*、*pair_style* 等)中定义的元素代号。 | 无     |
| E_atom        | float    | 单原子能（粗略值），用于aenet中聚合能 $E_{coh}$ 计算          （$E_{tot}=\sum_{j=1}^NE_{atom}+E_{coh}$）。 | 见下   |
| stp_style     | str      | 指纹函数风格，用于定义笛卡尔坐标到指纹坐标的映射关系。       | 无     |
| nnodes        | list     | 定义神经网络隐藏层各层神经元个数                             | 无     |
| acfuns        | list     | 定义神经网络隐藏层各层激活函数，注意需要有nnodes列表的size需要与acfuns列表适配 | 无     |

***lammps_number***  该参数无缺省值。当 AenetLab 涉及任何 *dump* 或 *data* 格式文件的输入输出时，该参数必须指定。

---

***E_atom***  在 aenet 的训练集归一化过程中，会根据人为设定的 *MAXENERGY* 聚合能截断来剔除一些高能构型，因此真实数据集规模将同时取决于 *E_atom* 以及  *MAXENERGY* 。在AenetLab 中，这个截断能可以通过 *Train-maxenergy* 来设置，当该参数缺省或取 null 时，将不会剔除高能构型。 

AenetLab 中允许用户通过Taylor展开的方式将原子受力信息加入训练过程，只通过聚合能来作为高能判据已经不再合适，因此需要额外的力判据，其可以通过 *CreateDetails-Taylor-3D-fcut* 设置。另外如果用户将 *Create-taylor* 设置为true，那么 *Train-maxenergy* 将会被自动缺省，不会剔除高能构型，因此此时 *E_atom* 的值并不会直接影响训练结果。

*E_atom* 具有缺省值，它们被定义在 AenetLab 源文件目录下的 *jsons/atomic_info.json* 文件中。因此用户只需要直接设置该参数为 "default" 即可使用 AenetLab 内置的单原子能数据。有两种更改 *E_atom* 的方式，一种是直接对源文件中的 *atomic_info.json* 进行修改，这种修改将会直接应用于之后所有的训练过程；另一种是对配置文件 *template.json* 进行修改，这种修改只会应用于当前的 Lab 目录。

---

***stp_style*** 该参数无缺省值，目前可选的风格包括 *behler2011* 、 *Spherical_Chebyshev* 以及*Spherical* 。指纹函数是训练神经网络势能面的关键，作为神经网络的输入层，其表征能力与复杂程度决定了训练得到势能面的综合性能。指纹函数的风格一般分为两类，一类是过参型如 *behler2011* ，这类指纹函数需要用户手动进行调整测试；另一类为多项式型如 *Spherical_Chebyshev* ，采用多项式族组合的方法来构造指纹函数，这类指纹函数不仅不需要复杂的调参工作，在之前关于[序参量的研究](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.28.784)中也可以找到物理对应。因此我们建议使用第二类指纹函数。

---

***nnodes*** 该参数缺省值为**[30, 30]**，其必须由一个全整数列表来指明。该参数代表神经网络**隐藏层**的结构，例如[15, 15]就表示有两层隐藏层，每层都拥有15个神经元，这样一个形如N-15-15-1的网络结构就搭建好了，其中N为指纹函数特征矢量的长度。

***acfuns*** 该参数缺省值为**["swish", "swish"]**，其必须由一个全字符型列表来指明。该参数代表神经网络每一层神经元使用的非线性激活函数，目前可以选择的激活函数有 *tanh* 、 *sigmoid* 、*linear* 、*mtanh* 、*twist* 、 *relu* 、*swish* 、*elu* 、*selu* 、*lrelu* 以及 *softplus* 。

```
		!------------------------------------------------------------!
		!                                                            !
		!          change the activation function for a layer        !
		!                                                            !
		! Allowed function types are:                                !
		!                                                            !
		!   'tanh', 't' --> hyperbolic tangents                      !
		!   'sigmoid', 's' --> sigmoid function                      !
		!   'linear', 'l' --> linear function                        !
		!   'mtanh', 'm' --> modified (scaled) tanh                  !
		!   'twist','w' --> modified (scaled) tanh plus twisting term!
		!   'relu', 'r' --> rectified linear unit                    !
		!   'swish', 'sw' --> Google's swish function                !
		!   'elu', 'e' --> exponentional linear unit                 !
		!   'selu', 'se' --> scaled exponentional linear unit        !
		!   'lrelu', 'lr' --> leaky rectified linear unit            !
		!   'softplus', 'sp'  --> softplus function                  !
		!                                                            !
		!------------------------------------------------------------!
```

需要注意的是，虽然AenetLab允许不同的元素拥有不同的指纹函数风格以及神经网络结构，但是建议用户使它们尽可能保持一致，如上[例子](#example1)所示。因为不同的 指纹函数种类 与 神经网络结构 计算速度并不一致，速度差异很可能影响最终势函数的并行效率。

<a name="text3.2"></a>

### 3.2 Units

<a name="text3.3"></a>

### 3.3 Rrange

<a name="text3.4"></a>

### 3.4 TestPercent

<a name="text3.5"></a>

### 3.5 TestSeed

<a name="text3.6"></a>

### 3.6 Create



### 3.7 CreateDetails

<a name="text3.7.1"></a>

#### 3.7.1 LJDimer

<a name="text3.7.2"></a>

#### 3.7.2 OnlyTaylor

<a name="text3.7.3"></a>

#### 3.7.3 Disturb

<a name="text3.7.4"></a>

#### 3.7.4 VorInsert

<a name="text3.7.5"></a>

#### 3.7.5 ClusterCut

<a name="text3.7.6"></a>

#### 3.7.6 DumpSelect

<a name="text3.7.7"></a>

#### 3.7.7 Xml2xsfs

<a name="text3.7.8"></a>

#### 3.7.8 AbinitioMD

<a name="text3.7.9"></a>

#### 3.7.9 Vasp

<a name="text3.7.11"></a>

#### 3.7.10 VaspCustomized



<a name="text3.8"></a>

### 3.8 Generate

<a name="text3.9"></a>

### 3.9 StpDetails

<a name="text3.10"></a>

### 3.10 Train

<a name="text3.11"></a>

### 3.11 TrainDetails

<a name="text3.12"></a>

### 3.12 PlotSave



<a name="text4"></a>

## 4 工作脚本

工作脚本是 AenetLab 内置的常用功能脚本，几乎覆盖所有的势能面训练所需的操作。其存在的意义是为了让用户能够从获取数据 、移动文件、测试绘图这些重复且繁琐的工作中解放出来，将更多的时间与精力投入更有意义的势能面优化训练中。**注意：所有的工作脚本，都必须在 [Lab目录](#text2.0) 下执行。**

<a name="text4.1"></a>

### 4.1 get_crystals.py

该脚本基于 Materials Project MAPI 的 pymatgen 实现，用户可以通过命令行参数来控制想要获得的晶体构形。目前该脚本仅支持针对 “元素” 这一标签的搜索。

|     命令行参数     | 值类型 | 是否支持多参 | 是否必选 |
| :----------------: | :----: | :----------: | :------: |
|    -s/--symbol     | 字符型 |     支持     |    是    |
| -oc/--onlycompound | 逻辑型 |    不支持    |    否    |
**示例1**：

```
python get_crystals.py -s Ga N
```

该语句会实现从 Materials Project 的数据集中找到所有上述两种（或一种）元素组成的化合物（包含单质）晶体构型，并存放在当前目录下的一个名为 `GaN` 的子目录中。

**示例2：**

```
python get_crystals.py -s Ga N -oc
```

该语句会实现从 Materials Project 的数据集中找到所有上述两种元素组成的化合物晶体构型（不包含单质），并存放在当前目录下的一个名为 `GaN` 的子目录中。

**注意：**该脚本想要正常使用，需要保证其运行环境可以发起 http 访问。对于集群或者未配置网络的服务器，基于安全性的考虑，建议用户在本地联网环境中配置 **pymatgen库** 与 **MAPI调用接口**（见 **1.2** 与 **1.3** 节）。由于该脚本并不依赖于 AenetLab ，因此用户可以直接在本地运行该脚本，之后再手动将得到的晶体结构目录上传到集群环境并放置在相应的lab目录下。

<a name="text4.2"></a>

### 4.2 earlystop.py

该脚本用于检查训练是否出现过拟合现象，并从训练记录中选择使测试集误差达到最小的一个训练步输出作为最终的输出。

| 命令行参数 | 值类型 | 是否支持多参 | 是否必选 |
| :--------: | :----: | :----------: | :------: |
| -i/--index |  整型  |      否      |    否    |

**示例1-训练中止的情况**

```
python earlystop.py
```

当某一训练任务被中止时，其中所有的训练生成文件将统一存放在公共的 [训练目录](#text2.0) 下。此时可如上示例1，此时脚本会自动搜寻当前训练任务的编号并判断该任务是否为一个续算任务（判断是否存在 "当前编号_step_details" 目录以及其内是否存在 *Info_train* 文件）。

如果是，则自动将该任务的训练信息与之前的训练信息合并，并从训练记录中选择**使测试集误差达到最小**的一个训练步势函数文件作为最终的输出存放到对应编号的势函数目录中，并输出记录该训练步误差信息的 *info* 文件。

如果不是，则创建 "当前编号_step_details" 目录，并执行相同的判断选择操作。

**示例2-训练完成的情况**

```
python earlystop.py -i 1
```

当测试误差收敛到极小或训练步数达到了设定的最大值(通过 *Train-iterations* 设置)，训练会自动完成，此时 AenetLab 将会把训练记录存放在 "编号_step_details" 目录，并将最后一个训练步的势函数文件存放在对应编号的势函数目录中，并标记本次训练任务完成。

在训练目录中，此时可能存在多次已完成的训练任务的记录，因此必须给脚本指定针对哪一个编号的训练任务进行操作。示例2中，将会为 "1_step_details" 进行操作，结果将放置在 "1_nnpots" 中。

<a name="text4.3"></a>

### 4.3 validate.py

该脚本用于生成/指定验证集，并输出验证结果。其中 -i/-nnp 与 -a/-scp 是两对互斥的参数。

当用户想要指定的势函数文件位于当前 Lab 的训练目录下时，可以使用 -i 简洁地完成指定相应训练任务的序号；否则，必须使用  -nnp 来详细指定势函数文件的路径。

当用户需要生成验证集时，使用 -a 即可。脚本会根据当前 Lab 目录中的参数json文件(template.json)中指定的数据集创建风格以及相关参数全新生成验证集，用户可以通过参数修改手段来自定义，见 [2.2](#text2.2)。注意：并不是所有的风格都适合这么做，目前仅支持 *Disturb*, *VorInsert*,  *ClusterCut* 以及 *AbinitioMD* 。

当用户需要指定验证集时，使用 -scp 即可。脚本会直接链接该参数给出的地址，并直接识别地址中的 *list* 文件或是 *.xsf* 后缀的文件。这里的链接方法与 2.4 中链接数据集的方法有些许不同： 2.4 中的方法则只需用户指定 Lab 目录，程序可以自动搜寻其下的数据集目录；而此处用户必须指定具体的数据集目录作为验证集。因此，在使用该功能时，请务必保证：**指定的数据集目录满足 [2.4](#text2.4) 中的数据集规范**。

另外，可以使用 -vb 这个参数来增加输出信息的详细程度。如果不使用该参数，输出信息将只包含统计平均后的单位原子误差信息；使用该参数则可以具体地输出精确到每一个原子上的误差。

|   命令行参数    |  值类型  | 是否支持多参 | 是否必选 |
| :-------------: | :------: | :----------: | :------: |
| -vb/--verbosity | 无需赋值 |      -       |    否    |
|   -i/--index    |   整型   |      否      |    否    |
|  -a/--addition  |   整型   |      否      |    否    |
|  -nnp/--nnpath  |  字符型  |      否      |    否    |
|  -scp/--scpath  |  字符型  |      否      |    否    |

**示例1：**

```
python validate.py -i 1 -a 100 -vb
```

该语句实现的功能为：使用当前 Lab 目录下的训练目录中 *1_nnpots* 的势函数文件作为待检验文件；并根据相关配置风格与参数创建100个全新的构型，并经过 DFT 计算后生成验证数据集，该数据集以 “*Validate_*风格_set”的方式命名；计算验证集上每一个构型的能量与每一个原子的力预测误差，并详细输出在 *Info_validation* 文件中，该文件将保存在验证集目录下。

**示例2：**

```
python validate.py -nnp path/to/nnfiles -scp path/to/validation/set
```

该语句实现的功能为：使用指定路径下的势函数文件作为待检验文件；使用指定路径下的数据集目录作为验证集；计算平均每原子能量与力的误差，并输出在 *Info_validation* 文件中，该文件将保存在验证集目录下。

---

*当前该工作脚本目前仅支持串行运行，并行版本将在后续的版本中发布*

<a name="text4.4"></a>

### 4.4 plot_dimer.py

该脚本用于定性地测试势函数文件是否具有真实的物理图像。因为神经网络势与对势具有相似的计算结构，因此神经网络势应该大致地还原出对势曲线的线形，如 2.6 中的[dimer曲线](#dimer)。使用该脚本可以快速绘制势函数文件中，各元素对的对势曲线，可以根据绘制结果来判断数据集中的键对分布，并做出适当的调整。

| 命令行参数 | 值类型 | 是否支持多参 | 是否必选 |
| :--------: | :----: | :----------: | :------: |
| -i/--index |  整型  |      否      |    是    |

 **示例：**

```
python plot_dimer.py -i 1
```

该语句实现的功能为：搜寻当前 Lab 目录下训练目录中序号为“1”的目录 *1_nnpots* ，使用其中的势函数文件对不同键长的原子对计算能量，最终绘制出对势曲线(默认以png格式存储，命名格式为"训练序号_nnpots-dimer.png")并存放于 Lab 目录下的 *plot* 子目录中。

---

可能遇到的问题：

1）**曲线未出现极小值**       这种情况一般是数据集中数据相似度太高导致的。直接将AIMD生成的构型全部加入数据集会引起该问题。



解决方案是：

一、控制采样间隔，以此来尽可能地减少相似度。这样做可以使数据集稀疏化，有利于神经网络学习到更多特征。如果数据集是采用 *AbinitioMD* 风格生成，那么可以设置 *nsamples* 来调控采样间隔，见 [3.7.8](#text3.7.8) 。

二、使用几何形变手段来人为改变键长分布。采用 *Disturb* 风格可以快速实现这一目标，见 [3.7.3](#text3.7.3) 。



2）**小键长时出现反物理图像**        这是由于数据集中某键对的数量少，且分布稀疏(通常在构造低浓度掺杂时会遇到这种情况)。



对此可以有针对性地建构一些小键长的构型(一般在0.9-1.5埃)，例如使用 *VorInsert* 风格可以更改其中的 *cls_size* 参数来控制插入原子所在的区域，以此构造局部高浓度的杂质构型。



3）**曲线的平台区不在零聚合能附近**      通常这意味着最终的训练结果并还未正确地收敛到物理解。一般训练步数设置过少，数据集规模不够或者数据集中存在极端高能构型时都会引起这种问题。


对此，可以相应地增加训练步数，扩大训练集相应键对数量以及清洗数据集。例如上图中，CuZr部分的势函数已经基本符合线形，但是显然O有关的势函数还未收敛，排查后发现是数据集中O相关的构型太少导致的，因此需要在原有数据集的基础上，增加更多的O相关的构型。

